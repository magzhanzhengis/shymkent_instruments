```markdown
# ğŸŒ… Zharnamai â€” AI Video Generation Pipeline

**Zharnamai** is a full-stack AI video pipeline that combines:
- ğŸ¥ **TwelveLabs** â€” for intelligent video analysis (description extraction)
- ğŸ§  **OpenAI GPT** â€” for creative text-to-video prompt generation
- ğŸŒˆ **Higgsfield** â€” for final video synthesis
- â˜ï¸ **Cloudinary** â€” for media upload and hosting
- âš¡ **FastAPI (Python)** backend
- ğŸ’» **Next.js + TailwindCSS** frontend (modern minimal UI)

---

## ğŸš€ Project Overview

Zharnamai allows users to:
1. Upload a **video** and a **reference image**  
2. Enter a **creative idea or text prompt**  
3. Automatically generate:
   - A video description via **TwelveLabs**
   - A creative text-to-video prompt via **OpenAI**
   - A generated AI video via **Higgsfield**

---

## ğŸ§© Architecture

```

Frontend (Next.js) â†’ FastAPI Backend â†’ TwelveLabs â†’ OpenAI â†’ Higgsfield â†’ Cloudinary

````

- **Frontend:** Minimalist UI for upload and interaction  
- **Backend:** Handles API orchestration and response parsing  
- **TwelveLabs:** Extracts key events / descriptions from the uploaded video  
- **OpenAI GPT:** Turns that description + user idea into a detailed cinematic prompt  
- **Higgsfield:** Uses the prompt to synthesize a new video  
- **Cloudinary:** Stores all uploaded media files  

---

## ğŸ› ï¸ Setup Guide

### 1ï¸âƒ£ Clone the project
```bash
git clone https://github.com/magzhanzhengis/shymkent_instruments.git
cd zharnamai
````

### 2ï¸âƒ£ Backend setup

```bash
cd backend
python -m venv venv
source venv/Scripts/activate   # on Windows
pip install -r requirements.txt
```

Create a `.env` file:

```
CLOUD_NAME=your_cloudinary_name
API_KEY=your_cloudinary_api_key
API_SECRET=your_cloudinary_api_secret

TWELVELABS_API_KEY=your_twelvelabs_api_key
TWELVELABS_INDEX_ID=auto

OPENAI_API_KEY=your_openai_api_key
HIGGSFIELD_API_KEY=your_higgsfield_api_key
```

Run the backend:

```bash
uvicorn main:app --reload --port 8001
```


Access UI â†’ [http://localhost:3000]

---

## âš¡ Usage

1. Open the Zharnamai UI
2. Upload a video and image
3. Enter your creative idea (example: *"A cinematic sunrise over Almaty mountains"*)
4. Click **Generate AI Video ğŸ¥**

The backend will:

1. Upload both files to Cloudinary
2. Create or reuse a TwelveLabs index
3. Send video for analysis â†’ retrieve a **description**
4. Send that description + idea to OpenAI â†’ generate a **text prompt**
5. Send that prompt to Higgsfield â†’ generate the final **AI video**

---

All the generated videos will be on higgsfield website

## ğŸª„ Design Philosophy

Zharnamai (Ğ–Ğ°Ñ€Ğ½Ğ°Ğ¼Ğ°Ğ¹) blends:

* âš¡ **Speed** â€” FastAPI + Next.js
* ğŸ§  **Creativity** â€” OpenAI-driven text imagination
* ğŸŒ… **Emotion** â€” Vibrant, warm UI colors
* ğŸ’ **Simplicity** â€” One-page upload & result flow

---

## ğŸ§¾ License

MIT License Â© 2025 Zharnamai Project

---

## ğŸ‘¨â€ğŸ’» Authors

* **Magzhan Zhenis** â€” Electrical & Computer Engineer
* FastAPI backend developer, frontend integration, AI orchestration

---

## â¤ï¸ Acknowledgements

* [TwelveLabs API](https://www.twelvelabs.io/)
* [OpenAI](https://platform.openai.com/)
* [Higgsfield](https://platform.higgsfield.ai/)
* [Cloudinary](https://cloudinary.com/)
* [Next.js](https://nextjs.org/)
* [FastAPI](https://fastapi.tiangolo.com/)

